{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'air_res': pd.read_csv('restaurant/air_reserve.csv',parse_dates=['visit_datetime','reserve_datetime']), \n",
    "    'hpg_res': pd.read_csv('restaurant/hpg_reserve.csv',parse_dates=['visit_datetime','reserve_datetime']), \n",
    "    'air_store': pd.read_csv('restaurant/air_store_info.csv'),\n",
    "    'hpg_store': pd.read_csv('restaurant/hpg_store_info.csv'),\n",
    "    'air_vis': pd.read_csv('restaurant/air_visit_data.csv',parse_dates=['visit_date']),\n",
    "    'store_id': pd.read_csv('restaurant/store_id_relation.csv'),\n",
    "    'sample_sub': pd.read_csv('restaurant/sample_submission.csv'),\n",
    "    'holiday_dates': pd.read_csv('restaurant/date_info.csv',parse_dates=['calendar_date']).rename(columns={'calendar_date':'visit_date'})\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['sample_sub']['air_store_id'] = data['sample_sub']['id'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['sample_sub']['visit_date'] = data['sample_sub']['id'].apply(lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['air_hpg_info'] = pd.merge(data['air_store'], data['hpg_store'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visitor each day\n",
    "plt1 = data['air_vis'].groupby(['visit_date'], as_index=False).agg({'visitors': np.sum})\n",
    "plt1=plt1.set_index('visit_date')\n",
    "plt1.plot(figsize=(15, 6))\n",
    "plt.ylabel(\"Sum of Visitors\")\n",
    "plt.title(\"Visitor each day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['air_vis'].groupby(['visit_date'], as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bar = data['air_store'].groupby(['air_genre_name'],as_index=False).count().sort_values(by='air_store_id',ascending=False)\n",
    "sns.barplot(y=bar['air_genre_name'], x=bar['air_store_id'], orient='h')\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(data['air_hpg_info'][['longitude','latitude']])\n",
    "data['air_hpg_info']['cluster'] = kmeans.predict(data['air_hpg_info'][['longitude','latitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['air_hpg_info'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_names = ['Tokyo','Osaka','Sapporo','Fukuoka','Niigata','Hiroshima','Shizouku','Hokkaido','Sendai','Kobe']\n",
    "hist_clust = data['air_store'].groupby(['cluster'],as_index=False).count()\n",
    "plt.figure(figsize=(9,10))\n",
    "plt.subplot(211)\n",
    "sns.barplot(x=cluster_names,y=air_hist_clust['air_store_id'])\n",
    "plt.subplot(212)\n",
    "sns.barplot(x=cluster_names,y=hpg_hist_clust['hpg_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  air_genre_name                 air_area_name  \\\n",
       "0  air_0f0cdeee6c9bf3d7  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "1  air_7cc17a324ae5c7dc  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "2  air_fee8dcf4d619598e  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "3  air_a17f0778617c76e2  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "4  air_83db5aff8f50478e  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "\n",
       "    latitude   longitude  \n",
       "0  34.695124  135.197852  \n",
       "1  34.695124  135.197852  \n",
       "2  34.695124  135.197852  \n",
       "3  34.695124  135.197852  \n",
       "4  35.658068  139.751599  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['air_store'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airid = data['air_store'].air_store_id\n",
    "hpgid = data['hpg_store'].hpg_store_id\n",
    "cluster_dict = {'air':[], 'hpg':[]}\n",
    "for t in range(0, 10):\n",
    "    cluster_dict[t] = {'air':[], 'hpg':[]}\n",
    "for i in range(0, len(airid)):\n",
    "    if (data_load['air_store'].loc[i, 'cluster'] == 0):       \n",
    "        cluster_dict[0]['air'].append(airid[i])\n",
    "    elif (data_load['air_store'].loc[i, 'cluster'] == 1):\n",
    "        cluster_dict[1]['air'].append(airid[i])\n",
    "    elif (data_load['air_store'].loc[i, 'cluster'] == 2):\n",
    "        cluster_dict[2]['air'].append(airid[i])\n",
    "    elif (data_load['air_store'].loc[i, 'cluster'] == 3):\n",
    "        cluster_dict[3]['air'].append(airid[i])\n",
    "    elif (data_load['air_store'].loc[i, 'cluster'] == 4):\n",
    "        cluster_dict[4]['air'].append(airid[i])\n",
    "    elif (data_load['air_store'].loc[i, 'cluster'] == 5):\n",
    "        cluster_dict[5]['air'].append(airid[i])\n",
    "    elif (data_load['air_store'].loc[i, 'cluster'] == 6):\n",
    "        cluster_dict[6]['air'].append(airid[i])\n",
    "    elif (data_load['air_store'].loc[i, 'cluster'] == 7):\n",
    "        cluster_dict[7]['air'].append(airid[i])\n",
    "    elif (data_load['air_store'].loc[i, 'cluster'] == 8):\n",
    "        cluster_dict[8]['air'].append(airid[i])\n",
    "    else:\n",
    "        cluster_dict[9]['air'].append(airid[i])\n",
    "\n",
    "# hpg cluster\n",
    "for i in range(0, len(hpgid)):\n",
    "    if (data_load['hpg_store'].loc[i, 'cluster'] == 0):       \n",
    "        cluster_dict[0]['hpg'].append(hpgid[i])\n",
    "    elif (data_load['hpg_store'].loc[i, 'cluster'] == 1):\n",
    "        cluster_dict[1]['hpg'].append(hpgid[i])\n",
    "    elif (data_load['hpg_store'].loc[i, 'cluster'] == 2):\n",
    "        cluster_dict[2]['hpg'].append(hpgid[i])\n",
    "    elif (data_load['hpg_store'].loc[i, 'cluster'] == 3):\n",
    "        cluster_dict[3]['hpg'].append(hpgid[i])\n",
    "    elif (data_load['hpg_store'].loc[i, 'cluster'] == 4):\n",
    "        cluster_dict[4]['hpg'].append(hpgid[i])\n",
    "    elif (data_load['hpg_store'].loc[i, 'cluster'] == 5):\n",
    "        cluster_dict[5]['hpg'].append(hpgid[i])\n",
    "    elif (data_load['hpg_store'].loc[i, 'cluster'] == 6):\n",
    "        cluster_dict[6]['hpg'].append(hpgid[i])\n",
    "    elif (data_load['hpg_store'].loc[i, 'cluster'] == 7):\n",
    "        cluster_dict[7]['hpg'].append(hpgid[i])\n",
    "    elif (data_load['hpg_store'].loc[i, 'cluster'] == 8):\n",
    "        cluster_dict[8]['hpg'].append(hpgid[i])\n",
    "    else:\n",
    "        cluster_dict[9]['hpg'].append(hpgid[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre = pd.read_csv('newtables/genre_match_info.csv')\n",
    "genre_temp = genre.set_index('air_genre', drop=False)\n",
    "genre_dict = {'air':[], 'hpg':[]}\n",
    "for i in range(0,len(genre.air_genre)):\n",
    "    genre_dict[i] = {'air':[], 'hpg':[]}\n",
    "    for j in range(0, len(airid)):\n",
    "        airgenre = data_load['air_store'].loc[j, 'air_genre_name']\n",
    "        if ('genre_'+airgenre == genre.air_genre[i]):\n",
    "            for m in range(0, len(hpgid)):\n",
    "                hpggenre = data_load['hpg_store'].loc[m, 'hpg_genre_name']\n",
    "                if (genre_temp.loc['genre_'+airgenre, 'genre_'+hpggenre] == 1 or airgenre == hpggenre):\n",
    "                    genre_dict[i]['air'].append(airid[j])\n",
    "                    genre_dict[i]['hpg'].append(hpgid[m])\n",
    "    print('Matching No.%d genre' %i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(genre_dict)-2):\n",
    "    genre_dict[i]['air'] = list(set(genre_dict[i]['air']))\n",
    "num = 0 \n",
    "for i in range(0,len(genre_dict)-2):\n",
    "    if (len(genre_dict[i]['air']) == 0):\n",
    "        num += 1\n",
    "        print(i)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "area_genre = {'air':[], 'hpg':[]}\n",
    "m = 0\n",
    "for i in range(0, len(cluster_dict)-2):\n",
    "    air_area_id = cluster_dict[i]['air']\n",
    "    hpg_area_id = cluster_dict[i]['hpg']\n",
    "    for j in range(0, len(genre_dict)-2):\n",
    "        air_genre_id = genre_dict[j]['air']\n",
    "        hpg_genre_id = genre_dict[j]['hpg']  \n",
    "        area_genre[m] = {'air':[], 'hpg':[], 'area':[], 'genre':[]}\n",
    "        if (len(air_genre_id) == 0):\n",
    "            area_genre[m]['area'].append(i)\n",
    "            area_genre[m]['genre'].append(genre.air_genre[j])\n",
    "            area_genre[m]['air'] = list(set(air_area_id).union(set(air_genre_id)))\n",
    "            area_genre[m]['hpg'] = list(set(hpg_area_id).union(set(hpg_genre_id)))         \n",
    "        else:\n",
    "            area_genre[m]['area'].append(i)\n",
    "            area_genre[m]['genre'].append(genre.air_genre[j])\n",
    "            area_genre[m]['air'] = list(set(air_area_id).intersection(set(air_genre_id)))\n",
    "            area_genre[m]['hpg'] = list(set(hpg_area_id).intersection(set(hpg_genre_id)))        \n",
    "        m += 1\n",
    "        end = (time.clock() - start) / 60\n",
    "        print('Matching No.%d area No.%d genre, time costed %s minutes' %(i,j,end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = 0 \n",
    "for i in range(0, len(area_genre)-2):\n",
    "    if (len(area_genre[i]['air']) == 0):\n",
    "        num += 1\n",
    "        print(i)\n",
    "print(num)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cluster_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(cluster_dict, f)\n",
    "with open('genre_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(genre_dict, f)\n",
    "with open('area_genre.pickle', 'wb') as f:\n",
    "    pickle.dump(area_genre, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train.pickle', 'rb') as r:\n",
    "    train = pickle.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(train, open('train_py2', 'wb'), protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
